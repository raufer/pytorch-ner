{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dressed-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/raulferreira/pytorch-ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "excited-communications",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "important-cooperative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=['ner', 'tagger', 'parser', 'textcat'])\n",
    "\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "promotional-implementation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "meaning-pioneer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "multiple-trainer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 0, 2: 0, 3: 0}\n"
     ]
    }
   ],
   "source": [
    "for a, b, c in char_offsets:\n",
    "    d = {i: c for i in range(a, b+1)}\n",
    "    print(d)\n",
    "    break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "plastic-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable=['ner', 'tagger', 'parser', 'textcat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "short-founder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'The SCE must send the registrar written notice of — \\n  ( a ) the initiation and termination of winding - up , including voluntary winding - up , liquidation or insolvency of the SCE or suspension of the SCE ’s payment procedures and any decision to continue operating the SCE ( within the meaning of Article 74 ) ; and \\n  ( b ) the closure of the branch , \\n  within one month of that event or decision .'\n",
    "doc = nlp(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "horizontal-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_offsets = [(token.idx, token.idx + len(token), token.i) for token in doc]\n",
    "\n",
    "char_index_to_token_index_mapping = reduce(\n",
    "    lambda acc, x: {**acc, **x},\n",
    "    [{i: c for i in range(a, b+1)} for a, b, c in char_offsets],\n",
    "    dict()\n",
    ")\n",
    "\n",
    "\n",
    "# for (a, b, c), t in zip(char_offsets, list(doc)):\n",
    "#     print(c, doc.text[a:b], '|', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "published-migration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 0,\n",
       " 2: 0,\n",
       " 3: 0,\n",
       " 4: 1,\n",
       " 5: 1,\n",
       " 6: 1,\n",
       " 7: 1,\n",
       " 8: 2,\n",
       " 9: 2,\n",
       " 10: 2,\n",
       " 11: 2,\n",
       " 12: 2,\n",
       " 13: 3,\n",
       " 14: 3,\n",
       " 15: 3,\n",
       " 16: 3,\n",
       " 17: 3,\n",
       " 18: 4,\n",
       " 19: 4,\n",
       " 20: 4,\n",
       " 21: 4,\n",
       " 22: 5,\n",
       " 23: 5,\n",
       " 24: 5,\n",
       " 25: 5,\n",
       " 26: 5,\n",
       " 27: 5,\n",
       " 28: 5,\n",
       " 29: 5,\n",
       " 30: 5,\n",
       " 31: 5,\n",
       " 32: 6,\n",
       " 33: 6,\n",
       " 34: 6,\n",
       " 35: 6,\n",
       " 36: 6,\n",
       " 37: 6,\n",
       " 38: 6,\n",
       " 39: 6,\n",
       " 40: 7,\n",
       " 41: 7,\n",
       " 42: 7,\n",
       " 43: 7,\n",
       " 44: 7,\n",
       " 45: 7,\n",
       " 46: 7,\n",
       " 47: 8,\n",
       " 48: 8,\n",
       " 49: 8,\n",
       " 50: 9,\n",
       " 51: 9,\n",
       " 52: 10,\n",
       " 53: 10,\n",
       " 54: 10,\n",
       " 55: 11,\n",
       " 56: 11,\n",
       " 57: 12,\n",
       " 58: 12,\n",
       " 59: 13,\n",
       " 60: 13,\n",
       " 61: 14,\n",
       " 62: 14,\n",
       " 63: 14,\n",
       " 64: 14,\n",
       " 65: 15,\n",
       " 66: 15,\n",
       " 67: 15,\n",
       " 68: 15,\n",
       " 69: 15,\n",
       " 70: 15,\n",
       " 71: 15,\n",
       " 72: 15,\n",
       " 73: 15,\n",
       " 74: 15,\n",
       " 75: 15,\n",
       " 76: 16,\n",
       " 77: 16,\n",
       " 78: 16,\n",
       " 79: 16,\n",
       " 80: 17,\n",
       " 81: 17,\n",
       " 82: 17,\n",
       " 83: 17,\n",
       " 84: 17,\n",
       " 85: 17,\n",
       " 86: 17,\n",
       " 87: 17,\n",
       " 88: 17,\n",
       " 89: 17,\n",
       " 90: 17,\n",
       " 91: 17,\n",
       " 92: 18,\n",
       " 93: 18,\n",
       " 94: 18,\n",
       " 95: 19,\n",
       " 96: 19,\n",
       " 97: 19,\n",
       " 98: 19,\n",
       " 99: 19,\n",
       " 100: 19,\n",
       " 101: 19,\n",
       " 102: 19,\n",
       " 103: 20,\n",
       " 104: 20,\n",
       " 105: 21,\n",
       " 106: 21,\n",
       " 107: 21,\n",
       " 108: 22,\n",
       " 109: 22,\n",
       " 110: 23,\n",
       " 111: 23,\n",
       " 112: 23,\n",
       " 113: 23,\n",
       " 114: 23,\n",
       " 115: 23,\n",
       " 116: 23,\n",
       " 117: 23,\n",
       " 118: 23,\n",
       " 119: 23,\n",
       " 120: 24,\n",
       " 121: 24,\n",
       " 122: 24,\n",
       " 123: 24,\n",
       " 124: 24,\n",
       " 125: 24,\n",
       " 126: 24,\n",
       " 127: 24,\n",
       " 128: 24,\n",
       " 129: 24,\n",
       " 130: 25,\n",
       " 131: 25,\n",
       " 132: 25,\n",
       " 133: 25,\n",
       " 134: 25,\n",
       " 135: 25,\n",
       " 136: 25,\n",
       " 137: 25,\n",
       " 138: 26,\n",
       " 139: 26,\n",
       " 140: 27,\n",
       " 141: 27,\n",
       " 142: 27,\n",
       " 143: 28,\n",
       " 144: 28,\n",
       " 145: 29,\n",
       " 146: 29,\n",
       " 147: 29,\n",
       " 148: 29,\n",
       " 149: 29,\n",
       " 150: 29,\n",
       " 151: 29,\n",
       " 152: 29,\n",
       " 153: 29,\n",
       " 154: 29,\n",
       " 155: 29,\n",
       " 156: 29,\n",
       " 157: 30,\n",
       " 158: 30,\n",
       " 159: 30,\n",
       " 160: 31,\n",
       " 161: 31,\n",
       " 162: 31,\n",
       " 163: 31,\n",
       " 164: 31,\n",
       " 165: 31,\n",
       " 166: 31,\n",
       " 167: 31,\n",
       " 168: 31,\n",
       " 169: 31,\n",
       " 170: 31,\n",
       " 171: 32,\n",
       " 172: 32,\n",
       " 173: 32,\n",
       " 174: 33,\n",
       " 175: 33,\n",
       " 176: 33,\n",
       " 177: 33,\n",
       " 178: 34,\n",
       " 179: 34,\n",
       " 180: 34,\n",
       " 181: 34,\n",
       " 182: 35,\n",
       " 183: 35,\n",
       " 184: 35,\n",
       " 185: 36,\n",
       " 186: 36,\n",
       " 187: 36,\n",
       " 188: 36,\n",
       " 189: 36,\n",
       " 190: 36,\n",
       " 191: 36,\n",
       " 192: 36,\n",
       " 193: 36,\n",
       " 194: 36,\n",
       " 195: 36,\n",
       " 196: 37,\n",
       " 197: 37,\n",
       " 198: 37,\n",
       " 199: 38,\n",
       " 200: 38,\n",
       " 201: 38,\n",
       " 202: 38,\n",
       " 203: 39,\n",
       " 204: 39,\n",
       " 205: 39,\n",
       " 206: 39,\n",
       " 207: 40,\n",
       " 208: 40,\n",
       " 209: 40,\n",
       " 210: 41,\n",
       " 211: 41,\n",
       " 212: 41,\n",
       " 213: 41,\n",
       " 214: 41,\n",
       " 215: 41,\n",
       " 216: 41,\n",
       " 217: 41,\n",
       " 218: 42,\n",
       " 219: 42,\n",
       " 220: 42,\n",
       " 221: 42,\n",
       " 222: 42,\n",
       " 223: 42,\n",
       " 224: 42,\n",
       " 225: 42,\n",
       " 226: 42,\n",
       " 227: 42,\n",
       " 228: 42,\n",
       " 229: 43,\n",
       " 230: 43,\n",
       " 231: 43,\n",
       " 232: 43,\n",
       " 233: 44,\n",
       " 234: 44,\n",
       " 235: 44,\n",
       " 236: 44,\n",
       " 237: 45,\n",
       " 238: 45,\n",
       " 239: 45,\n",
       " 240: 45,\n",
       " 241: 45,\n",
       " 242: 45,\n",
       " 243: 45,\n",
       " 244: 45,\n",
       " 245: 45,\n",
       " 246: 46,\n",
       " 247: 46,\n",
       " 248: 46,\n",
       " 249: 47,\n",
       " 250: 47,\n",
       " 251: 47,\n",
       " 252: 47,\n",
       " 253: 47,\n",
       " 254: 47,\n",
       " 255: 47,\n",
       " 256: 47,\n",
       " 257: 47,\n",
       " 258: 48,\n",
       " 259: 48,\n",
       " 260: 48,\n",
       " 261: 48,\n",
       " 262: 48,\n",
       " 263: 48,\n",
       " 264: 48,\n",
       " 265: 48,\n",
       " 266: 48,\n",
       " 267: 48,\n",
       " 268: 49,\n",
       " 269: 49,\n",
       " 270: 49,\n",
       " 271: 49,\n",
       " 272: 50,\n",
       " 273: 50,\n",
       " 274: 50,\n",
       " 275: 50,\n",
       " 276: 51,\n",
       " 277: 51,\n",
       " 278: 52,\n",
       " 279: 52,\n",
       " 280: 52,\n",
       " 281: 52,\n",
       " 282: 52,\n",
       " 283: 52,\n",
       " 284: 52,\n",
       " 285: 53,\n",
       " 286: 53,\n",
       " 287: 53,\n",
       " 288: 53,\n",
       " 289: 54,\n",
       " 290: 54,\n",
       " 291: 54,\n",
       " 292: 54,\n",
       " 293: 54,\n",
       " 294: 54,\n",
       " 295: 54,\n",
       " 296: 54,\n",
       " 297: 55,\n",
       " 298: 55,\n",
       " 299: 55,\n",
       " 300: 56,\n",
       " 301: 56,\n",
       " 302: 56,\n",
       " 303: 56,\n",
       " 304: 56,\n",
       " 305: 56,\n",
       " 306: 56,\n",
       " 307: 56,\n",
       " 308: 57,\n",
       " 309: 57,\n",
       " 310: 57,\n",
       " 311: 58,\n",
       " 312: 58,\n",
       " 313: 59,\n",
       " 314: 59,\n",
       " 315: 60,\n",
       " 316: 60,\n",
       " 317: 60,\n",
       " 318: 60,\n",
       " 319: 61,\n",
       " 320: 61,\n",
       " 321: 61,\n",
       " 322: 62,\n",
       " 323: 62,\n",
       " 324: 63,\n",
       " 325: 63,\n",
       " 326: 64,\n",
       " 327: 64,\n",
       " 328: 65,\n",
       " 329: 65,\n",
       " 330: 65,\n",
       " 331: 65,\n",
       " 332: 66,\n",
       " 333: 66,\n",
       " 334: 66,\n",
       " 335: 66,\n",
       " 336: 66,\n",
       " 337: 66,\n",
       " 338: 66,\n",
       " 339: 66,\n",
       " 340: 67,\n",
       " 341: 67,\n",
       " 342: 67,\n",
       " 343: 68,\n",
       " 344: 68,\n",
       " 345: 68,\n",
       " 346: 68,\n",
       " 347: 69,\n",
       " 348: 69,\n",
       " 349: 69,\n",
       " 350: 69,\n",
       " 351: 69,\n",
       " 352: 69,\n",
       " 353: 69,\n",
       " 354: 70,\n",
       " 355: 70,\n",
       " 356: 71,\n",
       " 357: 71,\n",
       " 358: 71,\n",
       " 359: 72,\n",
       " 360: 72,\n",
       " 361: 72,\n",
       " 362: 72,\n",
       " 363: 72,\n",
       " 364: 72,\n",
       " 365: 72,\n",
       " 366: 73,\n",
       " 367: 73,\n",
       " 368: 73,\n",
       " 369: 73,\n",
       " 370: 74,\n",
       " 371: 74,\n",
       " 372: 74,\n",
       " 373: 74,\n",
       " 374: 74,\n",
       " 375: 74,\n",
       " 376: 75,\n",
       " 377: 75,\n",
       " 378: 75,\n",
       " 379: 76,\n",
       " 380: 76,\n",
       " 381: 76,\n",
       " 382: 76,\n",
       " 383: 76,\n",
       " 384: 77,\n",
       " 385: 77,\n",
       " 386: 77,\n",
       " 387: 77,\n",
       " 388: 77,\n",
       " 389: 77,\n",
       " 390: 78,\n",
       " 391: 78,\n",
       " 392: 78,\n",
       " 393: 79,\n",
       " 394: 79,\n",
       " 395: 79,\n",
       " 396: 79,\n",
       " 397: 79,\n",
       " 398: 79,\n",
       " 399: 79,\n",
       " 400: 79,\n",
       " 401: 79,\n",
       " 402: 80,\n",
       " 403: 80}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_index_to_token_index_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "tamil-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/Users/raulferreira/pytorch-ner/data/prodigy-sample-annotation.pickle'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "metallic-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "reverse-wealth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The SCE must send the registrar written notice of — \\n  ( a ) the initiation and termination of winding - up , including voluntary winding - up , liquidation or insolvency of the SCE or suspension of the SCE ’s payment procedures and any decision to continue operating the SCE ( within the meaning of Article 74 ) ; and \\n  ( b ) the closure of the branch , \\n  within one month of that event or decision .'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([i['text'] for i in df.iloc[0]['tokens']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "conventional-concentrate",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [json.loads(d) for d in df['data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "grand-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entries = [(d['text'], d['spans']) for d in data]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.iloc[100:].to_pickle('/Users/raulferreira/pytorch-ner/data/prodigy-sample-annotation.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "strong-hacker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the court officer'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"the court officer must drive away if applicable\"\n",
    "sentence[0:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "difficult-refund",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    'This is a sentence',\n",
    "    \"the court officer must drive away if applicable\"\n",
    "]\n",
    "\n",
    "tokenizer(\n",
    "            texts,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=20,\n",
    "    return_offsets_mapping=True\n",
    "        )\n",
    "\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "coordinate-tuner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[100]['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "capital-canal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'the', 'Ġcourt', 'Ġofficer', 'Ġmust', 'Ġdrive', 'Ġaway', '</s>']\n",
      "[0, 627, 461, 1036, 531, 1305, 409, 2]\n",
      "[(0, 0), (0, 3), (4, 9), (10, 17), (18, 22), (23, 28), (29, 33), (0, 0)]\n",
      "<s> (0, 0)\n",
      "the (0, 3)\n",
      "Ġcourt (4, 9)\n",
      "Ġofficer (10, 17)\n",
      "Ġmust (18, 22)\n",
      "Ġdrive (23, 28)\n",
      "Ġaway (29, 33)\n",
      "</s> (0, 0)\n"
     ]
    }
   ],
   "source": [
    "sentence =  \"the court officer must drive away if applicable\"\n",
    "sentence = \"the court officer must drive away\"\n",
    "\n",
    "enc = tokenizer.encode_plus(sentence, return_offsets_mapping=True)\n",
    "\n",
    "print(tokenizer.convert_ids_to_tokens(enc['input_ids']))\n",
    "\n",
    "print(enc['input_ids'])\n",
    "print(enc['offset_mapping'])\n",
    "\n",
    "for a, b in zip(tokenizer.convert_ids_to_tokens(enc['input_ids']), enc['offset_mapping']):\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "thrown-projector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 34002, 6645, 409, 2]\n",
      "{'input_ids': [0, 34002, 6645, 409, 2], 'attention_mask': [1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 3), (3, 7), (8, 12), (0, 0)]}\n",
      "['<s>', 'Dri', 'ving', 'Ġaway', '</s>']\n"
     ]
    }
   ],
   "source": [
    "enc = tokenizer.encode_plus(\"Driving away\", return_offsets_mapping=True)\n",
    "\n",
    "print(enc['input_ids'])\n",
    "print(enc)\n",
    "\n",
    "print(tokenizer.convert_ids_to_tokens(enc['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "obvious-rebound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 133, 208, 8041, 531, 2142, 5, 19886, 17254, 1982, 3120, 9, 93, 1437, 50118, 36, 10, 4839, 5, 34939, 8, 17829, 9, 20058, 111, 62, 2156, 217, 11659, 20058, 111, 62, 2156, 6936, 1258, 50, 23799, 2987, 4469, 9, 5, 208, 8041, 50, 5436, 9, 5, 208, 8041, 44, 27, 29, 3207, 6196, 8, 143, 568, 7, 535, 1633, 5, 208, 8041, 36, 624, 5, 3099, 9, 6776, 6657, 4839, 25606, 8, 1437, 50118, 36, 741, 4839, 5, 6803, 9, 5, 6084, 2156, 1437, 50118, 624, 65, 353, 9, 14, 515, 50, 568, 479, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 3), (4, 5), (5, 7), (8, 12), (13, 17), (18, 21), (22, 28), (28, 31), (32, 39), (40, 46), (47, 49), (50, 51), (52, 52), (52, 53), (54, 55), (56, 57), (58, 59), (60, 63), (64, 74), (75, 78), (79, 90), (91, 93), (94, 101), (102, 103), (104, 106), (107, 108), (109, 118), (119, 128), (129, 136), (137, 138), (139, 141), (142, 143), (144, 150), (150, 155), (156, 158), (159, 164), (164, 167), (167, 169), (170, 172), (173, 176), (177, 178), (178, 180), (181, 183), (184, 194), (195, 197), (198, 201), (202, 203), (203, 205), (206, 207), (206, 207), (207, 208), (209, 216), (217, 227), (228, 231), (232, 235), (236, 244), (245, 247), (248, 256), (257, 266), (267, 270), (271, 272), (272, 274), (275, 276), (277, 283), (284, 287), (288, 295), (296, 298), (299, 306), (307, 309), (310, 311), (312, 313), (314, 317), (318, 318), (318, 319), (320, 321), (322, 323), (324, 325), (326, 329), (330, 337), (338, 340), (341, 344), (345, 351), (352, 353), (354, 354), (354, 355), (356, 362), (363, 366), (367, 372), (373, 375), (376, 380), (381, 386), (387, 389), (390, 398), (399, 400), (0, 0)]}\n"
     ]
    }
   ],
   "source": [
    "enc = tokenizer.encode_plus(data[100]['text'], return_offsets_mapping=True)\n",
    "print(enc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "minute-assessment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizer\n",
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "\n",
    "def make_roberta_tokenizer() -> PreTrainedTokenizer:\n",
    "    tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "tokenizer = make_roberta_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "southwest-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nlp(\"The court officer was driving away\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "linear-petersburg",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'court', 'officer', 'was', 'driving', 'away']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(i) for i in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "spiritual-mixer",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-6302a9332c48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The aerodynamics of the viature are well studied\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "sentence = \"The aerodynamics of the viature are well studied\"\n",
    "\n",
    "sentence[48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "capable-diamond",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "v = np.array([\n",
    "    [1, 1, 2],\n",
    "    [2, 3, 6]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "logical-sister",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5 2.  4. ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(v.mean(axis=0))\n",
    "np.argmax(v.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "relevant-approval",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.17716151475906372, 0.3453901410102844, 0.6674686074256897],\n",
       " [0.6000826954841614, 0.3614288568496704, 0.9698708057403564],\n",
       " [0.23562955856323242, 0.4113318920135498, 0.17610770463943481],\n",
       " [0.2445020079612732, 0.9833195209503174, 0.6258184909820557],\n",
       " [0.08503538370132446, 0.029334187507629395, 0.8442292213439941],\n",
       " [0.12422728538513184, 0.43789583444595337, 0.2543674111366272],\n",
       " [0.27070826292037964, 0.8785005211830139, 0.9738351106643677],\n",
       " [0.5133657455444336, 0.3527209162712097, 0.17843478918075562],\n",
       " [0.03944045305252075, 0.7657544016838074, 0.9044941067695618],\n",
       " [0.0683826208114624, 0.9502130150794983, 0.780992329120636]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Out[42].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "amber-supervision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1772, 0.3454, 0.6675],\n",
       "        [0.6001, 0.3614, 0.9699],\n",
       "        [0.2356, 0.4113, 0.1761],\n",
       "        [0.2445, 0.9833, 0.6258],\n",
       "        [0.0850, 0.0293, 0.8442],\n",
       "        [0.1242, 0.4379, 0.2544],\n",
       "        [0.2707, 0.8785, 0.9738],\n",
       "        [0.5134, 0.3527, 0.1784],\n",
       "        [0.0394, 0.7658, 0.9045],\n",
       "        [0.0684, 0.9502, 0.7810]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "torch.rand(10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "prerequisite-contest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'The', 'Ġaer', 'odynamics', 'Ġof', 'Ġthe', 'Ġvi', 'ature', 'Ġare', 'Ġwell', 'Ġstudied', '</s>']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 3),\n",
       " (4, 7),\n",
       " (7, 16),\n",
       " (17, 19),\n",
       " (20, 23),\n",
       " (24, 26),\n",
       " (26, 31),\n",
       " (32, 35),\n",
       " (36, 40),\n",
       " (41, 48),\n",
       " (0, 0)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"The aerodynamics of the viature are well studied\"\n",
    "\n",
    "encoded_tokens = ['<s>', 'The', 'Ġaer', 'odynamics', 'Ġof', 'Ġthe', 'Ġvi', 'ature', 'Ġare', 'Ġwell', 'Ġstudied', '</s>']\n",
    "\n",
    "input_ids = [0, 133, 16482, 41203, 9, 5, 12987, 18830, 32, 157, 8069, 2]\n",
    "\n",
    "offset_mapping = [\n",
    "    (0, 0),\n",
    "    (0, 3),\n",
    "    (4, 7),\n",
    "    (7, 16),\n",
    "    (17, 19),\n",
    "    (20, 23),\n",
    "    (24, 26),\n",
    "    (26, 31),\n",
    "    (32, 35),\n",
    "    (36, 40),\n",
    "    (41, 48),\n",
    "    (0, 0)\n",
    "]\n",
    "\n",
    "enc = tokenizer.encode_plus(sentence, return_offsets_mapping=True)\n",
    "\n",
    "print(tokenizer.convert_ids_to_tokens(enc['input_ids']))\n",
    "\n",
    "enc['offset_mapping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "intensive-paraguay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 34002, 6645, 409, 2]\n",
      "{'input_ids': [0, 34002, 6645, 409, 2], 'attention_mask': [1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 3), (3, 7), (8, 12), (0, 0)]}\n",
      "['<s>', 'Dri', 'ving', 'Ġaway', '</s>']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "enc = tokenizer.encode_plus(\"Driving away\", return_offsets_mapping=True, max_length=10, truncation=True)\n",
    "\n",
    "print(enc['input_ids'])\n",
    "print(enc)\n",
    "\n",
    "print(tokenizer.convert_ids_to_tokens(enc['input_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-recovery",
   "metadata": {},
   "source": [
    "target => torch.Size([16, 280])\n",
    "\n",
    "y_pred => torch.Size([16, 280, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "little-nature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "94\n",
      "94\n"
     ]
    }
   ],
   "source": [
    "ids = [    0, 13841,    10,  5375,     9,     5,  2502,    16,   829,    30,\n",
    "            5,  5644,    55,    87,   501,   360,   137,     5,  1248,   278,\n",
    "           13,     5,  1500,     7,  1642,  2156,     5,  5644,   531,  2156,\n",
    "          624,   501,   360,     9,     5, 18245,     9,     5,  2502,  2156,\n",
    "        18981,     5,    97,  1799,     7,     5,  7069,     8,     5,   461,\n",
    "          942,  1036,    11,  2410,   549,    50,    45,    93,  1437, 50118,\n",
    "           36,    10,  4839,    37, 20408,     5,  2502,  2156,  1311,  2188,\n",
    "           13,   143,   215,  1756, 25606,     8,  1437, 50118,    36,   741,\n",
    "         4839,    37,  8605,     7,    28,  4625,    23,   143,  1576,     9,\n",
    "            5,  2502,   479,     2]\n",
    "\n",
    "\n",
    "a = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "\n",
    "b = [-1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0, -1]\n",
    "\n",
    "print(len(ids))\n",
    "print(len(a))\n",
    "print(len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "clean-roads",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fct = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "pressed-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention_mask = torch.tensor([\n",
    "#     [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
    "#     [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
    "#     [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
    "# ])\n",
    "\n",
    "target = torch.tensor([\n",
    "    [-1, 1, 1, 1, -1, -1, -1, -1, -1, -1],\n",
    "    [-1, 1, 1, 1, 1, 1, 1, -1, -1, -1]  \n",
    "])\n",
    "\n",
    "logits = torch.tensor([\n",
    "    [[0.9672, 0.3671, 0.5196],\n",
    "     [0.7375, 0.4412, 0.6449],\n",
    "     [0.5044, 0.9435, 0.1143],\n",
    "     [0.9318, 0.8636, 0.8863],\n",
    "     [0.2648, 0.4413, 0.9613],\n",
    "     [0.7696, 0.5530, 0.9382],\n",
    "     [0.3856, 0.3141, 0.1020],\n",
    "     [0.0399, 0.5205, 0.3871],\n",
    "     [0.3224, 0.1528, 0.6944],\n",
    "     [0.1538, 0.6460, 0.5724]],\n",
    "\n",
    "    [[0.2613, 0.2959, 0.1332],\n",
    "     [0.0477, 0.4868, 0.9213],\n",
    "     [0.3568, 0.2871, 0.3812],\n",
    "     [0.2602, 0.8076, 0.6706],\n",
    "     [0.3575, 0.3397, 0.1995],\n",
    "     [0.5706, 0.7086, 0.0107],\n",
    "     [0.9112, 0.2669, 0.1066],\n",
    "     [0.2189, 0.0382, 0.3898],\n",
    "     [0.5111, 0.3911, 0.6043],\n",
    "     [0.3021, 0.5809, 0.4534]]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "closing-noise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "colonial-armor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9672, 0.3671, 0.5196],\n",
      "        [0.7375, 0.4412, 0.6449],\n",
      "        [0.5044, 0.9435, 0.1143],\n",
      "        [0.9318, 0.8636, 0.8863],\n",
      "        [0.2648, 0.4413, 0.9613],\n",
      "        [0.7696, 0.5530, 0.9382],\n",
      "        [0.3856, 0.3141, 0.1020],\n",
      "        [0.0399, 0.5205, 0.3871],\n",
      "        [0.3224, 0.1528, 0.6944],\n",
      "        [0.1538, 0.6460, 0.5724],\n",
      "        [0.2613, 0.2959, 0.1332],\n",
      "        [0.0477, 0.4868, 0.9213],\n",
      "        [0.3568, 0.2871, 0.3812],\n",
      "        [0.2602, 0.8076, 0.6706],\n",
      "        [0.3575, 0.3397, 0.1995],\n",
      "        [0.5706, 0.7086, 0.0107],\n",
      "        [0.9112, 0.2669, 0.1066],\n",
      "        [0.2189, 0.0382, 0.3898],\n",
      "        [0.5111, 0.3911, 0.6043],\n",
      "        [0.3021, 0.5809, 0.4534]])\n",
      "torch.Size([20, 3])\n",
      "\n",
      "tensor([-100,    1,    1,    1, -100, -100, -100, -100, -100, -100, -100,    1,\n",
      "           1,    1,    1,    1,    1, -100, -100, -100])\n",
      "torch.Size([20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0656657218933105"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_loss = target.view(-1) != -1 \n",
    "\n",
    "active_logits = logits.view(-1, 3)\n",
    "\n",
    "active_labels = torch.where(\n",
    "    active_loss, target.view(-1), torch.tensor(loss_fct.ignore_index).type_as(target)\n",
    ")\n",
    "\n",
    "print(active_logits)\n",
    "print(active_logits.shape)\n",
    "print()\n",
    "print(active_labels)\n",
    "print(active_labels.shape)\n",
    "loss = loss_fct(active_logits, active_labels)\n",
    "\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "special-shakespeare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-100,    1,    1,    1, -100, -100, -100, -100, -100, -100, -100,    1,\n",
       "           1,    1,    1,    1,    1, -100, -100, -100, -100,    1,    1, -100,\n",
       "        -100, -100, -100, -100, -100, -100])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "brilliant-classification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-100,    1,    1,    1, -100, -100, -100, -100, -100, -100, -100,    1,\n",
       "           1,    1,    1,    1,    1, -100, -100, -100, -100,    1,    1, -100,\n",
       "        -100, -100, -100, -100, -100, -100])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(\n",
    "    active_loss, target.view(-1), torch.tensor(loss_fct.ignore_index).type_as(target)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "active_labels = torch.where(\n",
    "    active_loss, target.view(-1), torch.tensor(loss_fct.ignore_index).type_as(target)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-contact",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "peaceful-voice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    [\n",
    "        [1, 2, 1],\n",
    "        [0, 1, 0],\n",
    "        [1, 1, 0],\n",
    "    ],\n",
    "    [\n",
    "        [0, 2, 0],\n",
    "        [0, 2, 0],\n",
    "        [2, 2, 0],\n",
    "    ]    \n",
    "]\n",
    "v = torch.tensor(data, dtype=float)\n",
    "\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "chief-request",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-0a3dd3757292>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for a, b in v:\n",
    "    print(a)\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accompanied-shield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6667, 1.3333, 0.3333], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.mean(dim=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "alpine-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle('/Users/raulferreira/pytorch-ner/data/prodigy-sample-annotation.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "congressional-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:50].to_pickle('/Users/raulferreira/pytorch-ner/data/prodigy-sample-annotation.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "artificial-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [[-1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], [-1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]]\n",
    "y_pred = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 2, 2, 0, 1, 1, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 2, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2, 1, 2, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 0, 1, 1, 0, 0, 2, 2, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 2, 0, 0, 0, 0, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 2, 2, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [1, 2, 2, 2, 1, 1, 1, 0, 1, 2, 0, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 0, 1, 1, 0, 1, 2, 1, 2, 0, 2, 2, 0, 0, 2, 1, 1, 1, 1, 1, 0, 0, 0, 2, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 0, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 2, 0, 0, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 1, 0, 0, 0, 2, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 2, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 2, 2, 0, 2, 0, 0, 1, 1, 2, 1, 1, 0, 0, 1, 1, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 1, 1, 1, 0, 2, 1, 2, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "abstract-delhi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(y_true))\n",
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "favorite-salon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_true[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "clear-little",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-record",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
